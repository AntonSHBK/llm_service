# Whisper + CTranslate2: Рейтинг по скорости (CPU)

| Ранг | Модель HF                                                                                                           | Размер / Квантование | Скорость на CPU | Точность       | Примечание                                               |
| ---- | ------------------------------------------------------------------------------------------------------------------- | -------------------- | --------------- | -------------- | -------------------------------------------------------- |
| 1    | [Systran/faster-whisper-base](https://huggingface.co/Systran/faster-whisper-base)                                   | FP16 (CTranslate2)   | Очень быстрая   | Низкая/средняя | Подходит для работы в реальном времени, минимум ресурсов |
| 2    | [Zoont/faster-whisper-large-v3-turbo-int8-ct2](https://huggingface.co/Zoont/faster-whisper-large-v3-turbo-int8-ct2) | INT8 (CTranslate2)   | Быстрая         | Высокая        | Лучший баланс между скоростью и точностью                |
| 3    | [Systran/faster-whisper-medium](https://huggingface.co/Systran/faster-whisper-medium)                               | FP16                 | Быстрая         | Хорошая        | Средний размер, быстрее large, точнее base               |
| 4    | [jvh/whisper-large-v3-quant-ct2](https://huggingface.co/jvh/whisper-large-v3-quant-ct2)                             | INT8 (CTranslate2)   | Средняя         | Очень высокая  | Эффективное квантование large-v3                         |
| 5    | [Systran/faster-whisper-large-v3](https://huggingface.co/Systran/faster-whisper-large-v3)                           | FP16                 | Медленная       | Максимальная   | Самая точная, но самая требовательная                    |

### Общая идея

Когда мы используем нейросеть для транскрибации аудио (например, Whisper), ключевая задача — подготовить звуковой сигнал в формате, который максимально подходит для модели, а также обеспечить стабильность работы на длинных записях. Для этого применяется **нормализация** и **разбиение на чанки**.

### Шаги алгоритма

1. **Загрузка аудио**
   Аудиофайл или поток открывается с помощью специализированной библиотеки (например, `pydub.AudioSegment`). Она поддерживает разные форматы (WAV, MP3, OGG) и преобразует их во внутреннее представление, с которым удобно работать.

2. **Нормализация**
   Чтобы модель работала корректно, аудио приводится к стандартному виду:

   * **частота дискретизации** — обычно 16 кГц,
   * **каналы** — моно (один канал),
   * **разрядность** — 16 бит (PCM).
     Это важно, потому что большинство моделей, включая Whisper, обучались именно на таком формате.

3. **Разбиение на чанки**
   Длинное аудио делится на небольшие куски фиксированной длины (например, по 30 секунд). Это делается для того, чтобы:

   * снизить нагрузку на процессор и память,
   * ускорить обработку (обрабатываются меньшие фрагменты),
   * уменьшить вероятность ошибок модели на длинных записях (галлюцинаций, потери текста).

   При разбиении каждый чанк хранится отдельно (например, во временном буфере).

4. **Обработка чанков моделью**
   Каждый чанк последовательно подаётся в модель распознавания речи. На выходе модель выдаёт список сегментов с текстом и временными метками.

5. **Сборка результата**
   Тексты из всех чанков объединяются в одну строку. При необходимости сохраняются и временные интервалы, что позволяет формировать субтитры или использовать расшифровку для навигации по записи.

### На что стоит обратить внимание

* **Размер чанка**:

  * Слишком маленький (5–10 секунд) → модель теряет контекст, могут обрываться слова.
  * Слишком большой (60+ секунд) → выше нагрузка и риск ошибок.
  * Практически оптимально 20–30 секунд.

* **Формат входного файла**:
  Лучше всегда приводить к WAV PCM 16 kHz mono. Это снижает риск ошибок и повышает скорость работы.

* **Пограничные эффекты**:
  Иногда слова обрезаются на стыке чанков. Чтобы избежать этого, используют **перекрытия** (например, добавляют по 1–2 секунды из предыдущего чанка к следующему).

* **Шумы и тишина**:
  Дополнительные фильтры (например, Voice Activity Detection) помогают убрать пустые участки и снизить количество ложных распознаваний.

* **Производительность**:

  * Нормализация и нарезка выполняются быстро, но тоже занимают время.
  * Основные затраты приходятся на обработку чанков моделью.
  * Логирование времени каждого шага помогает понять, где узкое место.
